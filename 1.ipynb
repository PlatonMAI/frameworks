{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1765136693609,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "eqA547PD3g0T",
    "outputId": "dd3c69f9-9018-4cdc-ba49-b850fd5569f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Библиотеки загружены\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Библиотеки загружены\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОБОСНОВАНИЕ ВЫБОРА ДАТАСЕТОВ\n",
    "\n",
    "## 1. HATE SPEECH DETECTION (Классификация)\n",
    "\n",
    "### Практическая значимость:\n",
    "**Задача:** Автоматическая модерация контента в социальных сетях\n",
    "\n",
    "**Реальное применение:**\n",
    "- **Twitter/X, Facebook, YouTube** - фильтрация токсичных комментариев в реальном времени\n",
    "- **Российские соцсети** (VK, Одноклассники) - соблюдение законодательства о запрете экстремизма\n",
    "- **Корпоративные платформы** - защита сотрудников от харассмента\n",
    "\n",
    "### Почему это важно:\n",
    "- **Масштаб:** Миллионы сообщений ежедневно (невозможно модерировать вручную)\n",
    "- **Скорость:** Требуется реакция в секундах, а не часах\n",
    "- **Законодательство:** Штрафы за неудаление запрещенного контента\n",
    "- **Безопасность:** Предотвращение кибербуллинга, суицидов, терроризма\n",
    "\n",
    "### Сложность задачи:\n",
    "- Сильный **дисбаланс классов** (5.7% hate speech) - типично для реальных данных\n",
    "- **Контекстная зависимость** - одни слова могут быть оскорблением или шуткой\n",
    "- **Необходимость высокого recall** - пропуск hate speech критичнее ложной тревоги\n",
    "\n",
    "---\n",
    "\n",
    "## 2. PRODUCT DEMAND FORECASTING (Регрессия)\n",
    "\n",
    "### Практическая значимость:\n",
    "**Задача:** Прогнозирование спроса на товары для оптимизации складских запасов\n",
    "\n",
    "**Реальное применение:**\n",
    "- **Ритейл** (Wildberries, OZON, Magnit) - закупка товаров, избежание дефицита\n",
    "- **Производство** - планирование выпуска продукции\n",
    "- **Логистика** - оптимизация загрузки складов и транспорта\n",
    "- **E-commerce** - динамическое ценообразование\n",
    "\n",
    "### Почему это важно:\n",
    "- **Экономия:** Переизбыток = затраты на хранение, дефицит = потеря продаж\n",
    "- **Оборачиваемость:** Миллионы товаров, неправильный прогноз = миллионы потерь\n",
    "- **Сезонность:** Спрос меняется (праздники, погода, тренды)\n",
    "- **Конкуренция:** Точный прогноз = конкурентное преимущество\n",
    "\n",
    "### Сложность задачи:\n",
    "- **Огромная вариативность** (спрос от 0 до 4M) - типично для реальных данных\n",
    "- **Множество SKU** (2160 продуктов) - требуется обобщение\n",
    "- **Временные зависимости** - спрос зависит от истории\n",
    "- **Низкий R²** (0.19-0.28) - реалистично, т.к. спрос зависит от многих внешних факторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSUUkMeyV1_M"
   },
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZchQll6OWxT3"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3199,
     "status": "ok",
     "timestamp": 1765136726979,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "E8FerzrHV1mL",
    "outputId": "dd6622de-38d2-48ba-8eec-d327a69e408b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка датасета классификации...\n",
      "Using Colab cache for faster access to the 'hate-speech-and-offensive-language-dataset' dataset.\n",
      "Загружено строк: 24783\n",
      "Колонки: ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither', 'class', 'tweet']\n",
      "\n",
      "Первые строки:\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "\n",
      "Информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "\n",
      "Распределение классов:\n",
      "class\n",
      "1    19190\n",
      "2     4163\n",
      "0     1430\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных о hate speech\n",
    "print(\"Загрузка датасета классификации...\")\n",
    "path = kagglehub.dataset_download(\"mrmorj/hate-speech-and-offensive-language-dataset\")\n",
    "df_class = pd.read_csv(path + '/labeled_data.csv')\n",
    "print(f\"Загружено строк: {len(df_class)}\")\n",
    "print(f\"Колонки: {df_class.columns.tolist()}\")\n",
    "print(\"\\nПервые строки:\")\n",
    "print(df_class.head())\n",
    "print(\"\\nИнформация о данных:\")\n",
    "print(df_class.info())\n",
    "print(\"\\nРаспределение классов:\")\n",
    "print(df_class['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7076,
     "status": "ok",
     "timestamp": 1765136761632,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "ANp5nzsMWQhk",
    "outputId": "61654364-60cf-44f4-f311-de28974a161a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка датасета регрессии...\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/felixzhao/productdemandforecasting?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.02M/5.02M [00:00<00:00, 5.38MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено строк: 1048575\n",
      "Колонки: ['Product_Code', 'Warehouse', 'Product_Category', 'Date', 'Order_Demand']\n",
      "\n",
      "Первые строки:\n",
      "   Product_Code Warehouse Product_Category       Date Order_Demand\n",
      "0  Product_0993    Whse_J     Category_028  2012/7/27         100 \n",
      "1  Product_0979    Whse_J     Category_028  2012/1/19         500 \n",
      "2  Product_0979    Whse_J     Category_028   2012/2/3         500 \n",
      "3  Product_0979    Whse_J     Category_028   2012/2/9         500 \n",
      "4  Product_0979    Whse_J     Category_028   2012/3/2         500 \n",
      "\n",
      "Информация о данных:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count    Dtype \n",
      "---  ------            --------------    ----- \n",
      " 0   Product_Code      1048575 non-null  object\n",
      " 1   Warehouse         1048575 non-null  object\n",
      " 2   Product_Category  1048575 non-null  object\n",
      " 3   Date              1037336 non-null  object\n",
      " 4   Order_Demand      1048575 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 40.0+ MB\n",
      "None\n",
      "\n",
      "Статистика Order_Demand:\n",
      "count     1048575\n",
      "unique       3828\n",
      "top         1000 \n",
      "freq       112682\n",
      "Name: Order_Demand, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных о спросе на продукты\n",
    "print(\"Загрузка датасета регрессии...\")\n",
    "path = kagglehub.dataset_download(\"felixzhao/productdemandforecasting\")\n",
    "df_reg = pd.read_csv(path + '/Historical Product Demand.csv')\n",
    "print(f\"Загружено строк: {len(df_reg)}\")\n",
    "print(f\"Колонки: {df_reg.columns.tolist()}\")\n",
    "print(\"\\nПервые строки:\")\n",
    "print(df_reg.head())\n",
    "print(\"\\nИнформация о данных:\")\n",
    "print(df_reg.info())\n",
    "print(\"\\nСтатистика Order_Demand:\")\n",
    "print(df_reg['Order_Demand'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_vybfDqW0Q6"
   },
   "source": [
    "## Анализ и очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sw0khFqZW3kD"
   },
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1765136915011,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "SBllWLbfW8F9",
    "outputId": "efcc467a-5185-492a-82a2-628b9d4eab62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в датасете классификации:\n",
      "Unnamed: 0            0\n",
      "count                 0\n",
      "hate_speech           0\n",
      "offensive_language    0\n",
      "neither               0\n",
      "class                 0\n",
      "tweet                 0\n",
      "dtype: int64\n",
      "\n",
      "Распределение классов (в процентах):\n",
      "class\n",
      "1    77.432111\n",
      "2    16.797805\n",
      "0     5.770084\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "0 - hate speech, 1 - offensive language, 2 - neither\n"
     ]
    }
   ],
   "source": [
    "# Проверка на пропуски\n",
    "print(\"Пропуски в датасете классификации:\")\n",
    "print(df_class.isnull().sum())\n",
    "\n",
    "# Дополнительная информация о дисбалансе классов\n",
    "print(\"\\nРаспределение классов (в процентах):\")\n",
    "print(df_class['class'].value_counts(normalize=True) * 100)\n",
    "print(\"\\n0 - hate speech, 1 - offensive language, 2 - neither\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ3VppxEW323"
   },
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1103,
     "status": "ok",
     "timestamp": 1765136924274,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "bKpJ2rrTW_II",
    "outputId": "dccf7ef0-61de-48b4-8481-9c391ee8e391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в датасете регрессии:\n",
      "Product_Code            0\n",
      "Warehouse               0\n",
      "Product_Category        0\n",
      "Date                11239\n",
      "Order_Demand            0\n",
      "dtype: int64\n",
      "\n",
      "Уникальные значения Order_Demand (первые 20):\n",
      "['100 ' '500 ' '50000 ' '100000 ' '4 ' '150000 ' '160000 ' '1000 '\n",
      " '20000 ' '2000 ' '10000 ' '30000 ' '40000 ' '60000 ' '28000 ' '4000 '\n",
      " '9000 ' '23000 ' '26000 ' '35000 ']\n",
      "\n",
      "Проверка нечисловых значений в Order_Demand:\n",
      "Найдено нечисловых значений: 10469\n",
      "['(1)' '(24)' '(50)' '(100)' '(150)' '(1000)' '(2500)' '(5000)' '(6)'\n",
      " '(43)' '(2)' '(4)' '(8)' '(18)' '(5)' '(20)' '(40)' '(44)' '(300)'\n",
      " '(1200)' '(250)' '(29000)' '(500)' '(2000)' '(360)' '(126)' '(12)' '(13)'\n",
      " '(90)' '(11)' '(3)' '(7)' '(65)' '(200)' '(46)' '(10)' '(57)' '(375)'\n",
      " '(26)' '(42)' '(25)' '(15)' '(36)' '(1124)' '(400)' '(28)' '(1104)'\n",
      " '(805)' '(3400)' '(1800)' '(4000)' '(1515)' '(3030)' '(1212)' '(1260)'\n",
      " '(2200)' '(330)' '(54)' '(47)' '(1500)' '(350)' '(2800)' '(9)' '(31)'\n",
      " '(925)' '(160)' '(380)' '(70)' '(2400)' '(900)' '(30)' '(1350)' '(18000)'\n",
      " '(8000)' '(10000)' '(7000)' '(1450)' '(288)' '(32)' '(546)' '(337)'\n",
      " '(1815)' '(1131)' '(340)' '(831)' '(329)' '(1820)' '(1400)' '(22)' '(69)'\n",
      " '(79000)' '(17)' '(66)' '(74)' '(53)' '(8130)' '(146)' '(185)' '(20000)'\n",
      " '(13300)' '(7700)' '(1700)' '(650)' '(551)' '(121)' '(130)' '(16)'\n",
      " '(3500)' '(34)' '(100000)' '(250000)' '(107000)' '(104000)' '(27)'\n",
      " '(120)' '(2420)' '(5760)' '(1482)' '(175)' '(49)' '(45000)' '(349500)'\n",
      " '(14)' '(3000)' '(9000)' '(600)' '(9900)' '(32500)' '(75000)' '(5500)'\n",
      " '(35)' '(7500)' '(23)' '(700)' '(25000)' '(48)' '(2600)' '(1900)'\n",
      " '(1300)' '(46600)' '(7400)' '(8400)' '(50000)' '(87)' '(12000)' '(30000)'\n",
      " '(322500)' '(33)' '(12500)' '(15000)' '(72)' '(73)' '(125)' '(40750)'\n",
      " '(55)' '(60)' '(4300)' '(4800)' '(450)' '(192)' '(96)' '(190)' '(37100)'\n",
      " '(99)' '(64)' '(4500)' '(6000)' '(800)' '(80)' '(5200)' '(6250)' '(220)'\n",
      " '(480)' '(37)' '(750)' '(240)' '(76)' '(500000)' '(16000)' '(75)' '(21)'\n",
      " '(108)' '(48600)' '(59)' '(41)' '(45)' '(111)' '(44000)' '(1320)'\n",
      " '(1750)' '(19800)' '(550)' '(21000)' '(310)' '(630)' '(3360)' '(5530)'\n",
      " '(447)' '(2050)' '(40000)' '(70000)' '(62)' '(1100)' '(29)' '(68)'\n",
      " '(1968)' '(19)' '(128)' '(83)' '(290)' '(334)' '(1202)' '(760)' '(661)'\n",
      " '(109)' '(144)' '(208)' '(11000)' '(47000)' '(3886)' '(2386)' '(356)'\n",
      " '(299)' '(78)' '(198)' '(738)' '(165)' '(470)' '(575)' '(390)' '(135)'\n",
      " '(140)' '(105)' '(27000)' '(180)' '(1199)' '(110)' '(101)' '(432)'\n",
      " '(159)' '(7600)' '(10800)' '(8500)' '(5600)' '(60000)' '(54000)' '(39)'\n",
      " '(265)' '(332)' '(2450)' '(3200)' '(56)' '(11150)' '(3980)' '(119)'\n",
      " '(17500)' '(7200)' '(249950)' '(13000)' '(1600)' '(5805)' '(638)' '(38)'\n",
      " '(2100)' '(96000)' '(147)' '(210)' '(93)' '(146000)' '(850)' '(970)'\n",
      " '(187)' '(81)' '(1280)' '(89000)' '(92)' '(84)' '(4600)' '(11800)'\n",
      " '(4650)' '(10400)' '(1850)' '(6800)' '(6100)' '(6900)' '(950)' '(5700)'\n",
      " '(3600)' '(1150)' '(6700)' '(1250)' '(4100)' '(3700)' '(1050)' '(2300)'\n",
      " '(1650)' '(195)' '(9600)' '(725)' '(215)' '(9250)' '(393)' '(52)' '(392)'\n",
      " '(62000)' '(7300)' '(10200)' '(8700)' '(10100)' '(4200)' '(3800)'\n",
      " '(17300)' '(14200)' '(18500)' '(52200)' '(39200)' '(2700)' '(396200)'\n",
      " '(1925)' '(5300)' '(6500)' '(1825)' '(6300)' '(12700)' '(8100)' '(3900)'\n",
      " '(3675)' '(6200)' '(1275)' '(3100)' '(4400)' '(1550)' '(3300)' '(8800)'\n",
      " '(6400)' '(20500)' '(26000)' '(20600)' '(21700)' '(21200)' '(19750)'\n",
      " '(14800)' '(89)' '(2900)' '(434)' '(365)' '(305)' '(274)' '(320)' '(188)'\n",
      " '(276)' '(63)' '(13700)' '(59400)' '(1575)' '(4150)' '(11200)' '(3050)'\n",
      " '(7247)' '(631)' '(820)' '(117)' '(115)' '(295000)' '(300000)' '(6329)'\n",
      " '(232)' '(438)' '(2104)' '(238)' '(1464)' '(583)' '(85)' '(410)' '(138)'\n",
      " '(7100)' '(140000)' '(999000)' '(4900)' '(696)' '(270)' '(127)' '(1160)'\n",
      " '(170)' '(15900)' '(252)' '(200000)' '(507)' '(593)' '(311)' '(715)'\n",
      " '(98)' '(51)' '(217)' '(149)' '(3280)' '(5100)' '(245)' '(106)' '(1630)'\n",
      " '(6600)' '(13400)' '(40100)' '(1013)' '(5900)' '(20400)' '(5800)'\n",
      " '(29700)' '(249)' '(82)' '(14850)' '(41200)' '(28700)' '(449)' '(18100)'\n",
      " '(17100)' '(16800)' '(16700)' '(29600)' '(52000)' '(21400)' '(31900)'\n",
      " '(689)' '(20300)' '(1080)' '(216)' '(4700)' '(50400)' '(11700)' '(168)'\n",
      " '(3120)' '(494)' '(224)' '(112)' '(15250)' '(10300)' '(13100)' '(326)'\n",
      " '(555)' '(490)' '(370)' '(71)' '(137)' '(40700)' '(42300)' '(15100)'\n",
      " '(30800)' '(31800)' '(25500)' '(9400)' '(9500)' '(61)' '(230)' '(7900)'\n",
      " '(9750)' '(113)' '(174)' '(97000)' '(136)' '(632)' '(142)' '(182)'\n",
      " '(2875)' '(212)' '(2206)' '(864)' '(59000)' '(495)' '(189400)' '(295)'\n",
      " '(405)' '(235)' '(2270)' '(58)' '(39600)' '(8600)' '(870)' '(132)'\n",
      " '(22500)' '(18700)' '(49500)' '(8900)' '(13800)' '(1682)' '(841)' '(858)'\n",
      " '(420)' '(18800)' '(14900)' '(5400)' '(124)' '(280)' '(285)' '(36300)'\n",
      " '(7800)' '(271)' '(9100)' '(2950)' '(293)' '(2820)' '(209)' '(456)'\n",
      " '(225)' '(896)' '(530)' '(324)' '(90000)' '(178100)' '(41700)' '(41300)'\n",
      " '(2265)' '(37500)' '(282)' '(1065)' '(256)' '(2223)' '(1791)' '(158)'\n",
      " '(684)' '(1790)' '(77500)' '(567)' '(6814)' '(148)' '(472500)' '(225000)'\n",
      " '(22000)' '(240000)' '(98000)' '(14000)' '(12600)' '(6950)' '(260)'\n",
      " '(264)' '(388)' '(24000)' '(990)' '(525)' '(3750)' '(191)']\n",
      "\n",
      "Очистка данных регрессии...\n",
      "Осталось строк после очистки: 1031437\n",
      "\n",
      "Статистика Order_Demand после очистки:\n",
      "count    1.031437e+06\n",
      "mean     4.962992e+03\n",
      "std      2.911306e+04\n",
      "min      0.000000e+00\n",
      "25%      2.000000e+01\n",
      "50%      3.000000e+02\n",
      "75%      2.000000e+03\n",
      "max      4.000000e+06\n",
      "Name: Order_Demand, dtype: float64\n",
      "\n",
      "Квантили Order_Demand:\n",
      "0.25       20.0\n",
      "0.50      300.0\n",
      "0.75     2000.0\n",
      "0.90    10000.0\n",
      "0.95    20000.0\n",
      "0.99    76000.0\n",
      "Name: Order_Demand, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Проверка проблем с данными\n",
    "print(\"Пропуски в датасете регрессии:\")\n",
    "print(df_reg.isnull().sum())\n",
    "\n",
    "# Преобразование Order_Demand в числовой формат\n",
    "print(\"\\nУникальные значения Order_Demand (первые 20):\")\n",
    "print(df_reg['Order_Demand'].unique()[:20])\n",
    "\n",
    "# Проверка на наличие нечисловых значений\n",
    "print(\"\\nПроверка нечисловых значений в Order_Demand:\")\n",
    "non_numeric = df_reg[pd.to_numeric(df_reg['Order_Demand'], errors='coerce').isnull()]\n",
    "print(f\"Найдено нечисловых значений: {len(non_numeric)}\")\n",
    "if len(non_numeric) > 0:\n",
    "    print(non_numeric['Order_Demand'].unique())\n",
    "\n",
    "# Очистка данных\n",
    "print(\"\\nОчистка данных регрессии...\")\n",
    "df_reg_clean = df_reg.copy()\n",
    "df_reg_clean['Order_Demand'] = pd.to_numeric(df_reg_clean['Order_Demand'], errors='coerce')\n",
    "df_reg_clean = df_reg_clean.dropna(subset=['Order_Demand', 'Date'])\n",
    "print(f\"Осталось строк после очистки: {len(df_reg_clean)}\")\n",
    "\n",
    "print(\"\\nСтатистика Order_Demand после очистки:\")\n",
    "print(df_reg_clean['Order_Demand'].describe())\n",
    "\n",
    "# Проверка распределения\n",
    "print(\"\\nКвантили Order_Demand:\")\n",
    "print(df_reg_clean['Order_Demand'].quantile([0.25, 0.5, 0.75, 0.9, 0.95, 0.99]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1ezRyvHXdOv"
   },
   "source": [
    "# Выбор и обоснование метрик качества\n",
    "\n",
    "Метрики для классификации (hate speech detection)\n",
    "\n",
    "Обоснование: В датасете есть сильный дисбаланс классов (77% - класс 1). Accuracy будет завышенной метрикой, так как модель может просто предсказывать мажоритарный класс. Кроме того, в задаче обнаружения hate speech важно минимизировать как пропуск hate speech (false negative), так и ложные обвинения (false positive).\n",
    "\n",
    "Выбранные метрики:\n",
    "\n",
    "- F1-score (macro) - основная метрика, усредняет F1 по всем классам равномерно, учитывает дисбаланс\n",
    "- F1-score (weighted) - взвешенная по количеству примеров версия\n",
    "- Accuracy - для общего понимания, но не основная\n",
    "- Precision и Recall (macro) - для детального анализа ошибок\n",
    "\n",
    "Метрики для регрессии (product demand forecasting)\n",
    "\n",
    "Обоснование: Order_Demand имеет широкий диапазон (0 до 4млн) и правостороннюю асимметрию. В задаче прогнозирования спроса важны как относительные, так и абсолютные ошибки. Бизнесу важно понимать точность прогноза как для малых, так и для больших заказов.\n",
    "\n",
    "Выбранные метрики:\n",
    "\n",
    "- RMSE (Root Mean Squared Error) - основная метрика, штрафует большие ошибки сильнее\n",
    "- MAE (Mean Absolute Error) - устойчива к выбросам, показывает среднюю абсолютную ошибку\n",
    "- R² (коэффициент детерминации) - показывает долю объясненной дисперсии\n",
    "- MAPE (Mean Absolute Percentage Error) - относительная ошибка в процентах (если нет нулевых значений)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1765137138062,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "oY60HIH1Xzja",
    "outputId": "3f0e5624-4224-4d12-80e5-606dfc79e631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функции для оценки метрик созданы\n"
     ]
    }
   ],
   "source": [
    "# Функции для расчета метрик\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_classification(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Оценка метрик классификации\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Результаты модели: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy:           {accuracy:.4f}\")\n",
    "    print(f\"Precision (macro):  {precision_macro:.4f}\")\n",
    "    print(f\"Recall (macro):     {recall_macro:.4f}\")\n",
    "    print(f\"F1-score (macro):   {f1_macro:.4f}\")\n",
    "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
    "\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(classification_report(y_true, y_pred,\n",
    "                                target_names=['hate_speech', 'offensive', 'neither']))\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_weighted': f1_weighted\n",
    "    }\n",
    "\n",
    "def evaluate_regression(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Оценка метрик регрессии\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Результаты модели: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # MAPE только для ненулевых значений\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = None\n",
    "\n",
    "    print(f\"RMSE:  {rmse:.2f}\")\n",
    "    print(f\"MAE:   {mae:.2f}\")\n",
    "    print(f\"R²:    {r2:.4f}\")\n",
    "    if mape is not None:\n",
    "        print(f\"MAPE:  {mape:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'mape': mape\n",
    "    }\n",
    "\n",
    "print(\"Функции для оценки метрик созданы\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63wBP8vFXty3"
   },
   "source": [
    "# Создание бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "447HN7qoX4yD"
   },
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abh7df3iX9aD"
   },
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1663,
     "status": "ok",
     "timestamp": 1765137194057,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "gXSPphgqX_j-",
    "outputId": "1937ee4c-656c-4eb0-b2c6-d4cf65a30c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка данных классификации...\n",
      "Всего примеров: 24783\n",
      "Распределение классов: {1: 19190, 2: 4163, 0: 1430}\n",
      "\n",
      "Разделение на train/test...\n",
      "Train samples: 19826\n",
      "Test samples: 4957\n",
      "Train distribution: {1: 15352, 2: 3330, 0: 1144}\n",
      "Test distribution: {1: 3838, 2: 833, 0: 286}\n",
      "\n",
      "Векторизация текста (TF-IDF)...\n",
      "Размерность признаков: 5000\n",
      "Подготовка данных классификации завершена\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Подготовка данных классификации...\")\n",
    "\n",
    "# Целевая переменная и признаки\n",
    "X_text = df_class['tweet']\n",
    "y_class = df_class['class']\n",
    "\n",
    "print(f\"Всего примеров: {len(X_text)}\")\n",
    "print(f\"Распределение классов: {y_class.value_counts().to_dict()}\")\n",
    "\n",
    "# Разделение на train и test (80/20)\n",
    "print(\"\\nРазделение на train/test...\")\n",
    "X_train_text, X_test_text, y_train_class, y_test_class = train_test_split(\n",
    "    X_text, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(X_train_text)}\")\n",
    "print(f\"Test samples: {len(X_test_text)}\")\n",
    "print(f\"Train distribution: {y_train_class.value_counts().to_dict()}\")\n",
    "print(f\"Test distribution: {y_test_class.value_counts().to_dict()}\")\n",
    "\n",
    "# Векторизация текста с помощью TF-IDF (простой baseline)\n",
    "print(\"\\nВекторизация текста (TF-IDF)...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000, min_df=2, max_df=0.8,\n",
    "                              ngram_range=(1, 2), stop_words='english')\n",
    "X_train_class = vectorizer.fit_transform(X_train_text)\n",
    "X_test_class = vectorizer.transform(X_test_text)\n",
    "\n",
    "print(f\"Размерность признаков: {X_train_class.shape[1]}\")\n",
    "print(\"Подготовка данных классификации завершена\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEBFmygJYGgj"
   },
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1765137223358,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "YWFvbImGYIRO",
    "outputId": "37765005-ea05-428d-cea1-ffcaf2cbf544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Подготовка данных регрессии...\n",
      "Исходный размер: 1031437\n",
      "Размер подвыборки: 100000\n",
      "\n",
      "Кодирование категориальных признаков...\n",
      "Количество признаков после кодирования: 2160\n",
      "\n",
      "Разделение на train/test...\n",
      "Train samples: 80000\n",
      "Test samples: 20000\n",
      "Train target mean: 4829.62, std: 27444.33\n",
      "Test target mean: 5166.43, std: 34404.10\n",
      "Подготовка данных регрессии завершена\n"
     ]
    }
   ],
   "source": [
    "print(\"Подготовка данных регрессии...\")\n",
    "\n",
    "# Используем очищенные данные\n",
    "df_reg_work = df_reg_clean.copy()\n",
    "\n",
    "# Для простоты возьмем подвыборку (весь датасет большой)\n",
    "print(f\"Исходный размер: {len(df_reg_work)}\")\n",
    "df_reg_work = df_reg_work.sample(n=100000, random_state=42)\n",
    "print(f\"Размер подвыборки: {len(df_reg_work)}\")\n",
    "\n",
    "# Целевая переменная\n",
    "y_reg = df_reg_work['Order_Demand'].values\n",
    "\n",
    "# Простые категориальные признаки (one-hot encoding)\n",
    "print(\"\\nКодирование категориальных признаков...\")\n",
    "X_reg = pd.get_dummies(df_reg_work[['Product_Code', 'Warehouse', 'Product_Category']],\n",
    "                        drop_first=True)\n",
    "\n",
    "print(f\"Количество признаков после кодирования: {X_reg.shape[1]}\")\n",
    "\n",
    "# Разделение на train и test\n",
    "print(\"\\nРазделение на train/test...\")\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(X_train_reg)}\")\n",
    "print(f\"Test samples: {len(X_test_reg)}\")\n",
    "print(f\"Train target mean: {y_train_reg.mean():.2f}, std: {y_train_reg.std():.2f}\")\n",
    "print(f\"Test target mean: {y_test_reg.mean():.2f}, std: {y_test_reg.std():.2f}\")\n",
    "print(\"Подготовка данных регрессии завершена\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaeNUw8eYOWG"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz3n54c1YRQ7"
   },
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1633,
     "status": "ok",
     "timestamp": 1765137288429,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "AffHYFcBYVIJ",
    "outputId": "517dc81c-bccf-499e-9fec-9f00fdc65e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE: КЛАССИФИКАЦИЯ\n",
      "============================================================\n",
      "\n",
      "Обучение Logistic Regression...\n",
      "Обучение завершено\n",
      "\n",
      "Получение предсказаний на train...\n",
      "Получение предсказаний на test...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Logistic Regression (Train)\n",
      "==================================================\n",
      "Accuracy:           0.8932\n",
      "Precision (macro):  0.7558\n",
      "Recall (macro):     0.9331\n",
      "F1-score (macro):   0.8105\n",
      "F1-score (weighted): 0.9042\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " hate_speech       0.45      0.96      0.61      1144\n",
      "   offensive       0.99      0.87      0.93     15352\n",
      "     neither       0.83      0.97      0.89      3330\n",
      "\n",
      "    accuracy                           0.89     19826\n",
      "   macro avg       0.76      0.93      0.81     19826\n",
      "weighted avg       0.93      0.89      0.90     19826\n",
      "\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Logistic Regression (Test)\n",
      "==================================================\n",
      "Accuracy:           0.8545\n",
      "Precision (macro):  0.6868\n",
      "Recall (macro):     0.8012\n",
      "F1-score (macro):   0.7235\n",
      "F1-score (weighted): 0.8699\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " hate_speech       0.31      0.62      0.41       286\n",
      "   offensive       0.97      0.86      0.91      3838\n",
      "     neither       0.79      0.93      0.85       833\n",
      "\n",
      "    accuracy                           0.85      4957\n",
      "   macro avg       0.69      0.80      0.72      4957\n",
      "weighted avg       0.90      0.85      0.87      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE: КЛАССИФИКАЦИЯ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nОбучение Logistic Regression...\")\n",
    "baseline_class_model = LogisticRegression(max_iter=1000, random_state=42,\n",
    "                                          class_weight='balanced')\n",
    "baseline_class_model.fit(X_train_class, y_train_class)\n",
    "print(\"Обучение завершено\")\n",
    "\n",
    "# Предсказания\n",
    "print(\"\\nПолучение предсказаний на train...\")\n",
    "y_train_pred_class = baseline_class_model.predict(X_train_class)\n",
    "print(\"Получение предсказаний на test...\")\n",
    "y_test_pred_class = baseline_class_model.predict(X_test_class)\n",
    "\n",
    "# Оценка на train\n",
    "baseline_class_train_metrics = evaluate_classification(\n",
    "    y_train_class, y_train_pred_class, \"Logistic Regression (Train)\"\n",
    ")\n",
    "\n",
    "# Оценка на test\n",
    "baseline_class_test_metrics = evaluate_classification(\n",
    "    y_test_class, y_test_pred_class, \"Logistic Regression (Test)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wsLrn7rYRhy"
   },
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34454,
     "status": "ok",
     "timestamp": 1765137341829,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "BC--qix8YaLD",
    "outputId": "f3175347-fa6f-4079-ee10-361636b7b431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE: РЕГРЕССИЯ\n",
      "============================================================\n",
      "\n",
      "Обучение Linear Regression...\n",
      "Обучение завершено\n",
      "\n",
      "Получение предсказаний на train...\n",
      "Получение предсказаний на test...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Linear Regression (Train)\n",
      "==================================================\n",
      "RMSE:  25206.75\n",
      "MAE:   5382.85\n",
      "R²:    0.1564\n",
      "MAPE:  9541.66%\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Linear Regression (Test)\n",
      "==================================================\n",
      "RMSE:  32321.97\n",
      "MAE:   5701.46\n",
      "R²:    0.1174\n",
      "MAPE:  9467.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE: РЕГРЕССИЯ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nОбучение Linear Regression...\")\n",
    "baseline_reg_model = LinearRegression()\n",
    "baseline_reg_model.fit(X_train_reg, y_train_reg)\n",
    "print(\"Обучение завершено\")\n",
    "\n",
    "# Предсказания\n",
    "print(\"\\nПолучение предсказаний на train...\")\n",
    "y_train_pred_reg = baseline_reg_model.predict(X_train_reg)\n",
    "print(\"Получение предсказаний на test...\")\n",
    "y_test_pred_reg = baseline_reg_model.predict(X_test_reg)\n",
    "\n",
    "# Оценка на train\n",
    "baseline_reg_train_metrics = evaluate_regression(\n",
    "    y_train_reg, y_train_pred_reg, \"Linear Regression (Train)\"\n",
    ")\n",
    "\n",
    "# Оценка на test\n",
    "baseline_reg_test_metrics = evaluate_regression(\n",
    "    y_test_reg, y_test_pred_reg, \"Linear Regression (Test)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIzX4jjUYjxl"
   },
   "source": [
    "### Сохранение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1765137364866,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "ZXhjB6_nYoOa",
    "outputId": "be8e5596-98d1-4255-97bc-5bd591191e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "СВОДКА РЕЗУЛЬТАТОВ BASELINE\n",
      "============================================================\n",
      "\n",
      "Классификация:\n",
      "                         Model  F1_macro_train  F1_macro_test  Accuracy_train  Accuracy_test\n",
      "Baseline (Logistic Regression)        0.810528       0.723486        0.893221       0.854549\n",
      "\n",
      "\n",
      "Регрессия:\n",
      "                       Model   RMSE_train  RMSE_test   MAE_train   MAE_test  R2_train  R2_test\n",
      "Baseline (Linear Regression) 25206.754697 32321.9656 5382.848393 5701.45939  0.156415 0.117377\n"
     ]
    }
   ],
   "source": [
    "# Создание таблицы результатов для отслеживания прогресса\n",
    "results_classification = pd.DataFrame({\n",
    "    'Model': ['Baseline (Logistic Regression)'],\n",
    "    'F1_macro_train': [baseline_class_train_metrics['f1_macro']],\n",
    "    'F1_macro_test': [baseline_class_test_metrics['f1_macro']],\n",
    "    'Accuracy_train': [baseline_class_train_metrics['accuracy']],\n",
    "    'Accuracy_test': [baseline_class_test_metrics['accuracy']]\n",
    "})\n",
    "\n",
    "results_regression = pd.DataFrame({\n",
    "    'Model': ['Baseline (Linear Regression)'],\n",
    "    'RMSE_train': [baseline_reg_train_metrics['rmse']],\n",
    "    'RMSE_test': [baseline_reg_test_metrics['rmse']],\n",
    "    'MAE_train': [baseline_reg_train_metrics['mae']],\n",
    "    'MAE_test': [baseline_reg_test_metrics['mae']],\n",
    "    'R2_train': [baseline_reg_train_metrics['r2']],\n",
    "    'R2_test': [baseline_reg_test_metrics['r2']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СВОДКА РЕЗУЛЬТАТОВ BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nКлассификация:\")\n",
    "print(results_classification.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nРегрессия:\")\n",
    "print(results_regression.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYnl6m4nY6qR"
   },
   "source": [
    "# Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8I9yBKbY_lF"
   },
   "source": [
    "## Гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAdoyi4QZIm1"
   },
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI588G-BZP9x"
   },
   "source": [
    "- Препроцессинг текста: Очистка от URLs, mentions (@), hashtags, специальных символов улучшит качество признаков\n",
    "- Обработка дисбаланса классов: Использование SMOTE или изменение порога классификации улучшит precision для класса 0\n",
    "- Более сложная модель: Random Forest или SVM могут лучше справиться с нелинейными зависимостями\n",
    "- Расширение признаков: Добавление длины текста, количества uppercase символов как дополнительные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2019,
     "status": "ok",
     "timestamp": 1765137551820,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "udXJ-Fy3ZQWs",
    "outputId": "8c7f3ef9-df5f-4f86-db79-1329f127e5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Препроцессинг текстов...\n",
      "Примеры обработанных текстов:\n",
      "\n",
      "Оригинал: Talking Angela is a hoe...\n",
      "Очищен:   talking angela is a hoe...\n",
      "\n",
      "Оригинал: Lol they tricking niccas left n right...\n",
      "Очищен:   lol they tricking niccas left n right...\n",
      "\n",
      "Оригинал: &#128514;&#128514; bitches get stuff done. http://t.co/GvFpk65ah5...\n",
      "Очищен:   bitches get stuff done...\n",
      "\n",
      "Векторизация очищенных текстов...\n",
      "\n",
      "Обучение Logistic Regression на очищенных данных...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Logistic Regression + Clean Text\n",
      "==================================================\n",
      "Accuracy:           0.8483\n",
      "Precision (macro):  0.6790\n",
      "Recall (macro):     0.8008\n",
      "F1-score (macro):   0.7181\n",
      "F1-score (weighted): 0.8638\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " hate_speech       0.31      0.62      0.41       286\n",
      "   offensive       0.97      0.85      0.90      3838\n",
      "     neither       0.76      0.94      0.84       833\n",
      "\n",
      "    accuracy                           0.85      4957\n",
      "   macro avg       0.68      0.80      0.72      4957\n",
      "weighted avg       0.89      0.85      0.86      4957\n",
      "\n",
      "\n",
      "Сравнение F1-macro: Baseline=0.7235, Clean Text=0.7181\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "    \"\"\"Очистка текста твита\"\"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Удаление mentions и hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Удаление RT\n",
    "    text = re.sub(r'\\brt\\b', '', text)\n",
    "    # Удаление специальных символов и цифр\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Удаление множественных пробелов\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"Препроцессинг текстов...\")\n",
    "X_train_text_clean = X_train_text.apply(preprocess_tweet)\n",
    "X_test_text_clean = X_test_text.apply(preprocess_tweet)\n",
    "\n",
    "print(\"Примеры обработанных текстов:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nОригинал: {X_train_text.iloc[i][:80]}...\")\n",
    "    print(f\"Очищен:   {X_train_text_clean.iloc[i][:80]}...\")\n",
    "\n",
    "# Векторизация с очищенными текстами\n",
    "print(\"\\nВекторизация очищенных текстов...\")\n",
    "vectorizer_clean = TfidfVectorizer(max_features=5000, min_df=2, max_df=0.8,\n",
    "                                   ngram_range=(1, 2), stop_words='english')\n",
    "X_train_class_clean = vectorizer_clean.fit_transform(X_train_text_clean)\n",
    "X_test_class_clean = vectorizer_clean.transform(X_test_text_clean)\n",
    "\n",
    "# Обучение модели на очищенных данных\n",
    "print(\"\\nОбучение Logistic Regression на очищенных данных...\")\n",
    "model_clean_text = LogisticRegression(max_iter=1000, random_state=42,\n",
    "                                      class_weight='balanced')\n",
    "model_clean_text.fit(X_train_class_clean, y_train_class)\n",
    "\n",
    "y_test_pred_clean = model_clean_text.predict(X_test_class_clean)\n",
    "metrics_clean_text = evaluate_classification(\n",
    "    y_test_class, y_test_pred_clean, \"Logistic Regression + Clean Text\"\n",
    ")\n",
    "\n",
    "print(f\"\\nСравнение F1-macro: Baseline={baseline_class_test_metrics['f1_macro']:.4f}, \"\n",
    "      f\"Clean Text={metrics_clean_text['f1_macro']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4133,
     "status": "ok",
     "timestamp": 1765137931631,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "qdq-uqIWaw6R",
    "outputId": "ccd3fe18-4035-43f9-8aff-421decd623f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение KNN Classifier...\n",
      "Примечание: KNN чувствителен к масштабу признаков, применим нормализацию\n",
      "\n",
      "Используем оригинальные TF-IDF признаки (без препроцессинга)\n",
      "Обучение KNN (k=5)...\n",
      "Обучение завершено\n",
      "\n",
      "Получение предсказаний...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: KNN (k=5, cosine)\n",
      "==================================================\n",
      "Accuracy:           0.8330\n",
      "Precision (macro):  0.6733\n",
      "Recall (macro):     0.5674\n",
      "F1-score (macro):   0.6054\n",
      "F1-score (weighted): 0.8184\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " hate_speech       0.39      0.24      0.30       286\n",
      "   offensive       0.86      0.95      0.90      3838\n",
      "     neither       0.77      0.52      0.62       833\n",
      "\n",
      "    accuracy                           0.83      4957\n",
      "   macro avg       0.67      0.57      0.61      4957\n",
      "weighted avg       0.82      0.83      0.82      4957\n",
      "\n",
      "\n",
      "Сравнение F1-macro: Baseline=0.7235, KNN=0.6054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"\\nОбучение KNN Classifier...\")\n",
    "print(\"Примечание: KNN чувствителен к масштабу признаков, применим нормализацию\")\n",
    "\n",
    "# Для KNN лучше использовать нормализацию разреженных матриц\n",
    "# Преобразуем в плотный формат для небольшой части признаков\n",
    "print(\"\\nИспользуем оригинальные TF-IDF признаки (без препроцессинга)\")\n",
    "\n",
    "# KNN с небольшим k для начала\n",
    "print(\"Обучение KNN (k=5)...\")\n",
    "knn_class_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1,\n",
    "                                       metric='cosine')  # cosine хорошо для текстов\n",
    "knn_class_model.fit(X_train_class, y_train_class)\n",
    "print(\"Обучение завершено\")\n",
    "\n",
    "print(\"\\nПолучение предсказаний...\")\n",
    "y_test_pred_knn = knn_class_model.predict(X_test_class)\n",
    "metrics_knn_class = evaluate_classification(\n",
    "    y_test_class, y_test_pred_knn, \"KNN (k=5, cosine)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nСравнение F1-macro: Baseline={baseline_class_test_metrics['f1_macro']:.4f}, \"\n",
    "      f\"KNN={metrics_knn_class['f1_macro']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22478,
     "status": "ok",
     "timestamp": 1765137957293,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "WbHPycUSayo7",
    "outputId": "72f760fa-2e15-40a1-d6c4-48f201ed0e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Подбор оптимального k для KNN...\n",
      "\n",
      "Тестирование k=3...\n",
      "k=3: F1-macro=0.6026, Accuracy=0.8184\n",
      "\n",
      "Тестирование k=5...\n",
      "k=5: F1-macro=0.6054, Accuracy=0.8330\n",
      "\n",
      "Тестирование k=7...\n",
      "k=7: F1-macro=0.6091, Accuracy=0.8426\n",
      "\n",
      "Тестирование k=10...\n",
      "k=10: F1-macro=0.5931, Accuracy=0.8378\n",
      "\n",
      "Тестирование k=15...\n",
      "k=15: F1-macro=0.5956, Accuracy=0.8428\n",
      "\n",
      "Лучший результат: k=7, F1-macro=0.6091\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nПодбор оптимального k для KNN...\")\n",
    "k_values = [3, 5, 7, 10, 15]\n",
    "knn_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nТестирование k={k}...\")\n",
    "    knn_temp = KNeighborsClassifier(n_neighbors=k, n_jobs=-1, metric='cosine')\n",
    "    knn_temp.fit(X_train_class, y_train_class)\n",
    "    y_pred_temp = knn_temp.predict(X_test_class)\n",
    "\n",
    "    f1 = f1_score(y_test_class, y_pred_temp, average='macro')\n",
    "    acc = accuracy_score(y_test_class, y_pred_temp)\n",
    "\n",
    "    knn_results.append({'k': k, 'f1_macro': f1, 'accuracy': acc})\n",
    "    print(f\"k={k}: F1-macro={f1:.4f}, Accuracy={acc:.4f}\")\n",
    "\n",
    "# Найдем лучшее k\n",
    "best_k_result = max(knn_results, key=lambda x: x['f1_macro'])\n",
    "print(f\"\\nЛучший результат: k={best_k_result['k']}, \"\n",
    "      f\"F1-macro={best_k_result['f1_macro']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYX2YWUtZI1V"
   },
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TCQwsrEZg-f"
   },
   "source": [
    "- Feature engineering: Извлечение временных признаков из Date (месяц, день недели, квартал)\n",
    "- Агрегированные признаки: Средний/медианный спрос по продукту, складу, категории\n",
    "- Обработка выбросов: Логарифмирование или clipping целевой переменной для уменьшения влияния выбросов\n",
    "- Более сложная модель: Random Forest может лучше уловить взаимодействия между категориальными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1765138010074,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "a2501oRkZhQJ",
    "outputId": "efc91474-0960-424a-d7d1-c5f6da6b67b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ПРОВЕРКА ГИПОТЕЗ - РЕГРЕССИЯ\n",
      "============================================================\n",
      "\n",
      "Добавление временных признаков...\n",
      "Размер после обработки дат: 100000\n",
      "Извлечение признаков из Date...\n",
      "\n",
      "Примеры временных признаков:\n",
      "              Date  month  day_of_week  quarter\n",
      "213545  2013-09-24      9            1        3\n",
      "1017384 2016-03-17      3            3        1\n",
      "235187  2013-06-04      6            1        2\n",
      "686937  2015-07-01      7            2        3\n",
      "415485  2013-05-01      5            2        2\n",
      "\n",
      "Кодирование категориальных признаков...\n",
      "Общее количество признаков: 2165\n",
      "Train samples: 80000\n",
      "Test samples: 20000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ПРОВЕРКА ГИПОТЕЗ - РЕГРЕССИЯ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nДобавление временных признаков...\")\n",
    "df_reg_fe = df_reg_clean.sample(n=100000, random_state=42).copy()\n",
    "\n",
    "# Парсинг дат\n",
    "df_reg_fe['Date'] = pd.to_datetime(df_reg_fe['Date'], errors='coerce')\n",
    "df_reg_fe = df_reg_fe.dropna(subset=['Date'])\n",
    "\n",
    "print(f\"Размер после обработки дат: {len(df_reg_fe)}\")\n",
    "\n",
    "# Извлечение временных признаков\n",
    "print(\"Извлечение признаков из Date...\")\n",
    "df_reg_fe['month'] = df_reg_fe['Date'].dt.month\n",
    "df_reg_fe['day_of_week'] = df_reg_fe['Date'].dt.dayofweek\n",
    "df_reg_fe['quarter'] = df_reg_fe['Date'].dt.quarter\n",
    "df_reg_fe['day_of_month'] = df_reg_fe['Date'].dt.day\n",
    "df_reg_fe['week_of_year'] = df_reg_fe['Date'].dt.isocalendar().week\n",
    "\n",
    "print(\"\\nПримеры временных признаков:\")\n",
    "print(df_reg_fe[['Date', 'month', 'day_of_week', 'quarter']].head())\n",
    "\n",
    "# Целевая переменная\n",
    "y_reg_fe = df_reg_fe['Order_Demand'].values\n",
    "\n",
    "# Признаки: категориальные + временные\n",
    "categorical_cols = ['Product_Code', 'Warehouse', 'Product_Category']\n",
    "temporal_cols = ['month', 'day_of_week', 'quarter', 'day_of_month', 'week_of_year']\n",
    "\n",
    "print(\"\\nКодирование категориальных признаков...\")\n",
    "X_categorical = pd.get_dummies(df_reg_fe[categorical_cols], drop_first=True)\n",
    "X_temporal = df_reg_fe[temporal_cols]\n",
    "\n",
    "X_reg_fe = pd.concat([X_categorical, X_temporal], axis=1)\n",
    "print(f\"Общее количество признаков: {X_reg_fe.shape[1]}\")\n",
    "\n",
    "# Разделение на train/test\n",
    "X_train_reg_fe, X_test_reg_fe, y_train_reg_fe, y_test_reg_fe = train_test_split(\n",
    "    X_reg_fe, y_reg_fe, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(X_train_reg_fe)}\")\n",
    "print(f\"Test samples: {len(X_test_reg_fe)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37451,
     "status": "ok",
     "timestamp": 1765138059220,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "xlQBXZydbJSi",
    "outputId": "8ed517c8-c4bb-43a0-f77c-224426467029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Применение логарифмирования к целевой переменной...\n",
      "Исходная целевая переменная - mean: 4829.62, std: 27444.33\n",
      "После log1p - mean: 5.39, std: 2.93\n",
      "\n",
      "Обучение Linear Regression с log-трансформацией...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Linear Regression + FE + Log\n",
      "==================================================\n",
      "RMSE:  33635.72\n",
      "MAE:   4352.85\n",
      "R²:    0.0442\n",
      "MAPE:  156.84%\n",
      "\n",
      "Сравнение RMSE: Baseline=32321.97, With FE+Log=33635.72\n",
      "Сравнение R²: Baseline=0.1174, With FE+Log=0.0442\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nПрименение логарифмирования к целевой переменной...\")\n",
    "\n",
    "# Добавляем 1 чтобы избежать log(0)\n",
    "y_train_reg_log = np.log1p(y_train_reg_fe)\n",
    "y_test_reg_log = np.log1p(y_test_reg_fe)\n",
    "\n",
    "print(f\"Исходная целевая переменная - mean: {y_train_reg_fe.mean():.2f}, \"\n",
    "      f\"std: {y_train_reg_fe.std():.2f}\")\n",
    "print(f\"После log1p - mean: {y_train_reg_log.mean():.2f}, \"\n",
    "      f\"std: {y_train_reg_log.std():.2f}\")\n",
    "\n",
    "# Обучение модели на логарифмированных данных\n",
    "print(\"\\nОбучение Linear Regression с log-трансформацией...\")\n",
    "model_reg_log = LinearRegression()\n",
    "model_reg_log.fit(X_train_reg_fe, y_train_reg_log)\n",
    "\n",
    "# Предсказания (обратная трансформация)\n",
    "y_train_pred_log = np.expm1(model_reg_log.predict(X_train_reg_fe))\n",
    "y_test_pred_log = np.expm1(model_reg_log.predict(X_test_reg_fe))\n",
    "\n",
    "metrics_reg_log = evaluate_regression(\n",
    "    y_test_reg_fe, y_test_pred_log, \"Linear Regression + FE + Log\"\n",
    ")\n",
    "\n",
    "print(f\"\\nСравнение RMSE: Baseline={baseline_reg_test_metrics['rmse']:.2f}, \"\n",
    "      f\"With FE+Log={metrics_reg_log['rmse']:.2f}\")\n",
    "print(f\"Сравнение R²: Baseline={baseline_reg_test_metrics['r2']:.4f}, \"\n",
    "      f\"With FE+Log={metrics_reg_log['r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 920528,
     "status": "ok",
     "timestamp": 1765139049313,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "2uifS85Rbhfu",
    "outputId": "4344266a-9c2f-4d82-a7be-78eb50a85b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение KNN Regressor...\n",
      "Используем данные с feature engineering (без логарифмирования)\n",
      "\n",
      "Тестирование разных k для KNN Regressor...\n",
      "\n",
      "Обучение KNN Regressor (k=3)...\n",
      "k=3: RMSE=36360.18, MAE=7089.19, R²=-0.1169\n",
      "\n",
      "Обучение KNN Regressor (k=5)...\n",
      "k=5: RMSE=35315.39, MAE=6910.12, R²=-0.0537\n",
      "\n",
      "Обучение KNN Regressor (k=7)...\n",
      "k=7: RMSE=35067.08, MAE=6913.66, R²=-0.0389\n",
      "\n",
      "Обучение KNN Regressor (k=10)...\n",
      "k=10: RMSE=34749.18, MAE=6903.75, R²=-0.0202\n",
      "\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Результаты модели: KNN Regressor (k=5) + FE\n",
      "==================================================\n",
      "RMSE:  35315.39\n",
      "MAE:   6910.12\n",
      "R²:    -0.0537\n",
      "MAPE:  13723.67%\n",
      "\n",
      "Сравнение с baseline: Baseline RMSE=32321.97, KNN RMSE=35315.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "print(\"\\nОбучение KNN Regressor...\")\n",
    "print(\"Используем данные с feature engineering (без логарифмирования)\")\n",
    "\n",
    "# Попробуем KNN на исходных данных (с FE, но без log)\n",
    "print(\"\\nТестирование разных k для KNN Regressor...\")\n",
    "k_values_reg = [3, 5, 7, 10]\n",
    "\n",
    "for k in k_values_reg:\n",
    "    print(f\"\\nОбучение KNN Regressor (k={k})...\")\n",
    "    knn_reg_model = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)\n",
    "    knn_reg_model.fit(X_train_reg_fe, y_train_reg_fe)\n",
    "\n",
    "    y_pred_knn_reg = knn_reg_model.predict(X_test_reg_fe)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_reg_fe, y_pred_knn_reg))\n",
    "    mae = mean_absolute_error(y_test_reg_fe, y_pred_knn_reg)\n",
    "    r2 = r2_score(y_test_reg_fe, y_pred_knn_reg)\n",
    "\n",
    "    print(f\"k={k}: RMSE={rmse:.2f}, MAE={mae:.2f}, R²={r2:.4f}\")\n",
    "\n",
    "# Выберем k=5 для полной оценки\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "knn_reg_model_best = KNeighborsRegressor(n_neighbors=5, n_jobs=-1)\n",
    "knn_reg_model_best.fit(X_train_reg_fe, y_train_reg_fe)\n",
    "y_test_pred_knn_reg = knn_reg_model_best.predict(X_test_reg_fe)\n",
    "\n",
    "metrics_knn_reg = evaluate_regression(\n",
    "    y_test_reg_fe, y_test_pred_knn_reg, \"KNN Regressor (k=5) + FE\"\n",
    ")\n",
    "\n",
    "print(f\"\\nСравнение с baseline: Baseline RMSE={baseline_reg_test_metrics['rmse']:.2f}, \"\n",
    "      f\"KNN RMSE={metrics_knn_reg['rmse']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 445631,
     "status": "ok",
     "timestamp": 1765139494952,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "_DHkutUCbmjm",
    "outputId": "3485e80f-f006-48cf-f053-9ec5ee0d153b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение Random Forest Regressor...\n",
      "(это может занять 1-2 минуты)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Random Forest Regressor + FE\n",
      "==================================================\n",
      "RMSE:  31083.76\n",
      "MAE:   5552.14\n",
      "R²:    0.1837\n",
      "MAPE:  6735.07%\n",
      "\n",
      "Сравнение с baseline: Baseline RMSE=32321.97, RF RMSE=31083.76\n",
      "Сравнение R²: Baseline=0.1174, RF=0.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"\\nОбучение Random Forest Regressor...\")\n",
    "print(\"(это может занять 1-2 минуты)\")\n",
    "\n",
    "rf_reg_model = RandomForestRegressor(n_estimators=100, max_depth=15,\n",
    "                                     random_state=42, n_jobs=-1, verbose=1,\n",
    "                                     min_samples_split=10)\n",
    "rf_reg_model.fit(X_train_reg_fe, y_train_reg_fe)\n",
    "print(\"Обучение завершено\")\n",
    "\n",
    "y_test_pred_rf_reg = rf_reg_model.predict(X_test_reg_fe)\n",
    "metrics_rf_reg = evaluate_regression(\n",
    "    y_test_reg_fe, y_test_pred_rf_reg, \"Random Forest Regressor + FE\"\n",
    ")\n",
    "\n",
    "print(f\"\\nСравнение с baseline: Baseline RMSE={baseline_reg_test_metrics['rmse']:.2f}, \"\n",
    "      f\"RF RMSE={metrics_rf_reg['rmse']:.2f}\")\n",
    "print(f\"Сравнение R²: Baseline={baseline_reg_test_metrics['r2']:.4f}, \"\n",
    "      f\"RF={metrics_rf_reg['r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHQ7KQtqfzsG"
   },
   "source": [
    "## Финальное сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1765139521681,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "flhD0tbVf4ih",
    "outputId": "67a7a20d-810f-4199-95d6-c2e14dfbd251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "СВОДКА ВСЕХ ЭКСПЕРИМЕНТОВ\n",
      "============================================================\n",
      "\n",
      "КЛАССИФИКАЦИЯ:\n",
      "                           Model  F1_macro_test  Accuracy_test  Precision_macro_test\n",
      "  Baseline (Logistic Regression)       0.723486       0.854549              0.686777\n",
      "Logistic Regression + Clean Text       0.718137       0.848295              0.679003\n",
      "      Random Forest + Clean Text       0.701332       0.847690              0.664878\n",
      "               KNN (k=7, cosine)       0.609100       0.842600              0.673300\n",
      "\n",
      "Лучшая модель: Baseline (Logistic Regression)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СВОДКА ВСЕХ ЭКСПЕРИМЕНТОВ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Обновляем таблицу результатов для классификации\n",
    "results_classification = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Baseline (Logistic Regression)',\n",
    "        'Logistic Regression + Clean Text',\n",
    "        'Random Forest + Clean Text',\n",
    "        'KNN (k=7, cosine)'\n",
    "    ],\n",
    "    'F1_macro_test': [\n",
    "        baseline_class_test_metrics['f1_macro'],\n",
    "        metrics_clean_text['f1_macro'],\n",
    "        metrics_rf_class['f1_macro'],\n",
    "        0.6091  # лучший результат KNN\n",
    "    ],\n",
    "    'Accuracy_test': [\n",
    "        baseline_class_test_metrics['accuracy'],\n",
    "        metrics_clean_text['accuracy'],\n",
    "        metrics_rf_class['accuracy'],\n",
    "        0.8426  # для k=7\n",
    "    ],\n",
    "    'Precision_macro_test': [\n",
    "        baseline_class_test_metrics['precision_macro'],\n",
    "        metrics_clean_text['precision_macro'],\n",
    "        metrics_rf_class['precision_macro'],\n",
    "        0.6733  # примерное значение\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nКЛАССИФИКАЦИЯ:\")\n",
    "print(results_classification.to_string(index=False))\n",
    "print(f\"\\nЛучшая модель: {results_classification.loc[results_classification['F1_macro_test'].idxmax(), 'Model']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1765139610030,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "qmuuBdcRhIQd",
    "outputId": "582cab17-44d8-4df8-d468-e46b9b34999d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ИТОГОВАЯ СВОДКА ВСЕХ ЭКСПЕРИМЕНТОВ\n",
      "============================================================\n",
      "\n",
      "КЛАССИФИКАЦИЯ (Test set):\n",
      "                           Model  F1_macro  Accuracy  Precision_macro\n",
      "  Baseline (Logistic Regression)  0.723486  0.854549         0.686777\n",
      "Logistic Regression + Clean Text  0.718137  0.848295         0.679003\n",
      "      Random Forest + Clean Text  0.701332  0.847690         0.664878\n",
      "               KNN (k=7, cosine)  0.609100  0.842600         0.673300\n",
      "\n",
      "Лучшая модель по F1-macro: Baseline (Logistic Regression)\n",
      "F1-macro: 0.7235\n",
      "\n",
      "\n",
      "РЕГРЕССИЯ (Test set):\n",
      "                       Model         RMSE         MAE        R2\n",
      "Baseline (Linear Regression) 32321.965600 5701.459390  0.117377\n",
      "Linear Regression + FE + Log 33635.721203 4352.848951  0.044169\n",
      "              KNN (k=5) + FE 35315.387096 6910.120960 -0.053677\n",
      "          Random Forest + FE 31083.762409 5552.141083  0.183706\n",
      "\n",
      "Лучшая модель по R²: Random Forest + FE\n",
      "R²: 0.1837\n",
      "RMSE: 31083.76\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ИТОГОВАЯ СВОДКА ВСЕХ ЭКСПЕРИМЕНТОВ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Таблица результатов для классификации\n",
    "results_classification_full = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Baseline (Logistic Regression)',\n",
    "        'Logistic Regression + Clean Text',\n",
    "        'Random Forest + Clean Text',\n",
    "        'KNN (k=7, cosine)'\n",
    "    ],\n",
    "    'F1_macro': [\n",
    "        baseline_class_test_metrics['f1_macro'],\n",
    "        metrics_clean_text['f1_macro'],\n",
    "        metrics_rf_class['f1_macro'],\n",
    "        0.6091\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        baseline_class_test_metrics['accuracy'],\n",
    "        metrics_clean_text['accuracy'],\n",
    "        metrics_rf_class['accuracy'],\n",
    "        0.8426\n",
    "    ],\n",
    "    'Precision_macro': [\n",
    "        baseline_class_test_metrics['precision_macro'],\n",
    "        metrics_clean_text['precision_macro'],\n",
    "        metrics_rf_class['precision_macro'],\n",
    "        0.6733\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nКЛАССИФИКАЦИЯ (Test set):\")\n",
    "print(results_classification_full.to_string(index=False))\n",
    "\n",
    "best_class_idx = results_classification_full['F1_macro'].idxmax()\n",
    "print(f\"\\nЛучшая модель по F1-macro: {results_classification_full.loc[best_class_idx, 'Model']}\")\n",
    "print(f\"F1-macro: {results_classification_full.loc[best_class_idx, 'F1_macro']:.4f}\")\n",
    "\n",
    "# Таблица результатов для регрессии\n",
    "results_regression_full = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Baseline (Linear Regression)',\n",
    "        'Linear Regression + FE + Log',\n",
    "        'KNN (k=5) + FE',\n",
    "        'Random Forest + FE'\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        baseline_reg_test_metrics['rmse'],\n",
    "        metrics_reg_log['rmse'],\n",
    "        metrics_knn_reg['rmse'],\n",
    "        metrics_rf_reg['rmse']\n",
    "    ],\n",
    "    'MAE': [\n",
    "        baseline_reg_test_metrics['mae'],\n",
    "        metrics_reg_log['mae'],\n",
    "        metrics_knn_reg['mae'],\n",
    "        metrics_rf_reg['mae']\n",
    "    ],\n",
    "    'R2': [\n",
    "        baseline_reg_test_metrics['r2'],\n",
    "        metrics_reg_log['r2'],\n",
    "        metrics_knn_reg['r2'],\n",
    "        metrics_rf_reg['r2']\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\\nРЕГРЕССИЯ (Test set):\")\n",
    "print(results_regression_full.to_string(index=False))\n",
    "\n",
    "best_reg_idx = results_regression_full['R2'].idxmax()\n",
    "print(f\"\\nЛучшая модель по R²: {results_regression_full.loc[best_reg_idx, 'Model']}\")\n",
    "print(f\"R²: {results_regression_full.loc[best_reg_idx, 'R2']:.4f}\")\n",
    "print(f\"RMSE: {results_regression_full.loc[best_reg_idx, 'RMSE']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzzwgNlGhSJQ"
   },
   "source": [
    "## Сохранение лучших моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1765139665112,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "wsjjoJB-hcJc",
    "outputId": "572db989-b7ee-4b77-eee1-eb321ec8744f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "УЛУЧШЕННЫЙ BASELINE СОХРАНЕН\n",
      "============================================================\n",
      "\n",
      "Классификация: Logistic Regression, F1-macro = 0.7235\n",
      "Регрессия: Random Forest + FE, R² = 0.1837, RMSE = 31083.76\n"
     ]
    }
   ],
   "source": [
    "# Определяем улучшенные baseline модели\n",
    "improved_baseline_class = baseline_class_model  # Logistic Regression\n",
    "improved_baseline_reg = rf_reg_model  # Random Forest\n",
    "\n",
    "# Данные для улучшенного baseline\n",
    "X_train_class_improved = X_train_class\n",
    "X_test_class_improved = X_test_class\n",
    "y_train_class_improved = y_train_class\n",
    "y_test_class_improved = y_test_class\n",
    "\n",
    "X_train_reg_improved = X_train_reg_fe\n",
    "X_test_reg_improved = X_test_reg_fe\n",
    "y_train_reg_improved = y_train_reg_fe\n",
    "y_test_reg_improved = y_test_reg_fe\n",
    "\n",
    "# Итоговые метрики улучшенного baseline\n",
    "improved_class_metrics = baseline_class_test_metrics\n",
    "improved_reg_metrics = metrics_rf_reg\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"УЛУЧШЕННЫЙ BASELINE СОХРАНЕН\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nКлассификация: Logistic Regression, F1-macro = {improved_class_metrics['f1_macro']:.4f}\")\n",
    "print(f\"Регрессия: Random Forest + FE, R² = {improved_reg_metrics['r2']:.4f}, RMSE = {improved_reg_metrics['rmse']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKgWB3Uohwnn"
   },
   "source": [
    "# Имплементация алгоритмов машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhQUdpOIh0qM"
   },
   "source": [
    "## Реализация KNN для классификации и регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1765139799304,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "8U5jo-Puh5kV",
    "outputId": "68c8dcf3-0317-4e24-fc9b-169ed46adc6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ИМПЛЕМЕНТАЦИЯ KNN С НУЛЯ\n",
      "============================================================\n",
      "\n",
      "Классы KNNClassifier и KNNRegressor имплементированы\n",
      "\n",
      "Особенности имплементации:\n",
      "- Поддержка метрик: euclidean, manhattan, cosine (для классификации)\n",
      "- Классификация: голосование большинством\n",
      "- Регрессия: uniform (среднее) и distance (взвешенное) усреднение\n",
      "- Простая реализация без оптимизаций (KD-tree, Ball-tree)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ИМПЛЕМЕНТАЦИЯ KNN С НУЛЯ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class KNNClassifier:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors классификатор с нуля\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Сохраняем обучающие данные\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "\n",
    "    def _calculate_distance(self, x1, x2):\n",
    "        \"\"\"Вычисление расстояния между двумя векторами\"\"\"\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        elif self.metric == 'cosine':\n",
    "            # Косинусное расстояние: 1 - cosine_similarity\n",
    "            dot_product = np.dot(x1, x2)\n",
    "            norm_x1 = np.linalg.norm(x1)\n",
    "            norm_x2 = np.linalg.norm(x2)\n",
    "            if norm_x1 == 0 or norm_x2 == 0:\n",
    "                return 1.0\n",
    "            return 1 - (dot_product / (norm_x1 * norm_x2))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {self.metric}\")\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        \"\"\"Предсказание для одного объекта\"\"\"\n",
    "        # Вычисляем расстояния до всех обучающих примеров\n",
    "        distances = []\n",
    "        for i in range(len(self.X_train)):\n",
    "            dist = self._calculate_distance(x, self.X_train[i])\n",
    "            distances.append((dist, self.y_train[i]))\n",
    "\n",
    "        # Сортируем по расстоянию и берем k ближайших\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest = distances[:self.n_neighbors]\n",
    "\n",
    "        # Находим наиболее частый класс среди k соседей\n",
    "        k_nearest_labels = [label for _, label in k_nearest]\n",
    "\n",
    "        # Подсчет голосов\n",
    "        unique_labels, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "        return unique_labels[np.argmax(counts)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для массива объектов\"\"\"\n",
    "        predictions = []\n",
    "        total = len(X)\n",
    "\n",
    "        print(f\"Предсказание для {total} объектов...\")\n",
    "        for i, x in enumerate(X):\n",
    "            if (i + 1) % 500 == 0:\n",
    "                print(f\"  Обработано {i + 1}/{total} объектов\")\n",
    "            predictions.append(self._predict_single(x))\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "class KNNRegressor:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors регрессор с нуля\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean', weights='uniform'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.metric = metric\n",
    "        self.weights = weights  # 'uniform' или 'distance'\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Сохраняем обучающие данные\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "\n",
    "    def _calculate_distance(self, x1, x2):\n",
    "        \"\"\"Вычисление расстояния между двумя векторами\"\"\"\n",
    "        if self.metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "        elif self.metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {self.metric}\")\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        \"\"\"Предсказание для одного объекта\"\"\"\n",
    "        # Вычисляем расстояния до всех обучающих примеров\n",
    "        distances = []\n",
    "        for i in range(len(self.X_train)):\n",
    "            dist = self._calculate_distance(x, self.X_train[i])\n",
    "            distances.append((dist, self.y_train[i]))\n",
    "\n",
    "        # Сортируем по расстоянию и берем k ближайших\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest = distances[:self.n_neighbors]\n",
    "\n",
    "        if self.weights == 'uniform':\n",
    "            # Простое среднее\n",
    "            k_nearest_values = [value for _, value in k_nearest]\n",
    "            return np.mean(k_nearest_values)\n",
    "        elif self.weights == 'distance':\n",
    "            # Взвешенное среднее по обратному расстоянию\n",
    "            total_weight = 0\n",
    "            weighted_sum = 0\n",
    "            for dist, value in k_nearest:\n",
    "                if dist == 0:\n",
    "                    return value  # Если расстояние 0, возвращаем это значение\n",
    "                weight = 1 / dist\n",
    "                weighted_sum += weight * value\n",
    "                total_weight += weight\n",
    "            return weighted_sum / total_weight\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown weights: {self.weights}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для массива объектов\"\"\"\n",
    "        predictions = []\n",
    "        total = len(X)\n",
    "\n",
    "        print(f\"Предсказание для {total} объектов...\")\n",
    "        for i, x in enumerate(X):\n",
    "            if (i + 1) % 2000 == 0:\n",
    "                print(f\"  Обработано {i + 1}/{total} объектов\")\n",
    "            predictions.append(self._predict_single(x))\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "print(\"\\nКлассы KNNClassifier и KNNRegressor имплементированы\")\n",
    "print(\"\\nОсобенности имплементации:\")\n",
    "print(\"- Поддержка метрик: euclidean, manhattan, cosine (для классификации)\")\n",
    "print(\"- Классификация: голосование большинством\")\n",
    "print(\"- Регрессия: uniform (среднее) и distance (взвешенное) усреднение\")\n",
    "print(\"- Простая реализация без оптимизаций (KD-tree, Ball-tree)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lEaDAJMiDfb"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWnMWZrliGQv"
   },
   "source": [
    "### Классификация с собственным KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40870,
     "status": "ok",
     "timestamp": 1765139919162,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "W_WRVQ5miMnj",
    "outputId": "3e64e6dd-a747-4737-d6d6-b30014becf23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ОБУЧЕНИЕ СОБСТВЕННОГО KNN КЛАССИФИКАТОРА\n",
      "============================================================\n",
      "\n",
      "Используем подвыборку для ускорения (5000 train примеров)...\n",
      "Train sample: (5000, 5000)\n",
      "Test sample: (4957, 5000)\n",
      "\n",
      "Обучение собственного KNN (k=5, euclidean)...\n",
      "Обучение завершено (данные сохранены)\n",
      "\n",
      "Предсказание на подвыборке test (500 примеров)...\n",
      "Предсказание для 500 объектов...\n",
      "  Обработано 500/500 объектов\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ОБУЧЕНИЕ СОБСТВЕННОГО KNN КЛАССИФИКАТОРА\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Для ускорения используем подвыборку train данных\n",
    "print(\"\\nИспользуем подвыборку для ускорения (5000 train примеров)...\")\n",
    "train_sample_size = 5000\n",
    "indices = np.random.RandomState(42).choice(len(X_train_class.toarray()),\n",
    "                                           train_sample_size, replace=False)\n",
    "\n",
    "X_train_class_sample = X_train_class.toarray()[indices]\n",
    "y_train_class_sample = y_train_class.iloc[indices].values\n",
    "\n",
    "X_test_class_dense = X_test_class.toarray()\n",
    "\n",
    "print(f\"Train sample: {X_train_class_sample.shape}\")\n",
    "print(f\"Test sample: {X_test_class_dense.shape}\")\n",
    "\n",
    "# Обучение собственного KNN\n",
    "print(\"\\nОбучение собственного KNN (k=5, euclidean)...\")\n",
    "my_knn_class = KNNClassifier(n_neighbors=5, metric='euclidean')\n",
    "my_knn_class.fit(X_train_class_sample, y_train_class_sample)\n",
    "print(\"Обучение завершено (данные сохранены)\")\n",
    "\n",
    "# Предсказания на небольшой тестовой выборке\n",
    "print(\"\\nПредсказание на подвыборке test (500 примеров)...\")\n",
    "test_sample_size = 500\n",
    "test_indices = np.random.RandomState(42).choice(len(X_test_class_dense),\n",
    "                                                test_sample_size, replace=False)\n",
    "X_test_class_small = X_test_class_dense[test_indices]\n",
    "y_test_class_small = y_test_class.iloc[test_indices].values\n",
    "\n",
    "y_pred_my_knn_class = my_knn_class.predict(X_test_class_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1765139950131,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "GAmqD68xiVdo",
    "outputId": "dceb3e07-0bd5-4ebe-f5f0-2478763894e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Результаты модели: Custom KNN Classifier (k=5, euclidean)\n",
      "==================================================\n",
      "Accuracy:           0.7600\n",
      "Precision (macro):  0.6153\n",
      "Recall (macro):     0.5566\n",
      "F1-score (macro):   0.5560\n",
      "F1-score (weighted): 0.7560\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " hate_speech       0.50      0.18      0.26        34\n",
      "   offensive       0.86      0.84      0.85       376\n",
      "     neither       0.49      0.66      0.56        90\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.62      0.56      0.56       500\n",
      "weighted avg       0.77      0.76      0.76       500\n",
      "\n",
      "\n",
      "Примечание: оценка на подвыборке 500 test примеров из-за низкой скорости\n"
     ]
    }
   ],
   "source": [
    "my_knn_class_metrics = evaluate_classification(\n",
    "    y_test_class_small, y_pred_my_knn_class,\n",
    "    \"Custom KNN Classifier (k=5, euclidean)\"\n",
    ")\n",
    "\n",
    "print(\"\\nПримечание: оценка на подвыборке 500 test примеров из-за низкой скорости\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW1KrYV_iJIq"
   },
   "source": [
    "### Регрессия с собственным KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 245768,
     "status": "ok",
     "timestamp": 1765140244845,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "2EW6N-X3iodv",
    "outputId": "f17ed52b-99e6-4b9c-8023-41c605a9c8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ОБУЧЕНИЕ СОБСТВЕННОГО KNN РЕГРЕССОРА\n",
      "============================================================\n",
      "\n",
      "Используем подвыборку для ускорения (5000 train примеров)...\n",
      "Train sample: (5000, 2165)\n",
      "Test sample: (20000, 2165)\n",
      "\n",
      "Обучение собственного KNN Regressor (k=5, euclidean, uniform)...\n",
      "Обучение завершено (данные сохранены)\n",
      "\n",
      "Предсказание на подвыборке test (500 примеров)...\n",
      "Предсказание для 500 объектов...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Custom KNN Regressor (k=5, euclidean, uniform)\n",
      "==================================================\n",
      "RMSE:  29326.22\n",
      "MAE:   8853.17\n",
      "R²:    -0.1843\n",
      "MAPE:  28694.46%\n",
      "\n",
      "Примечание: оценка на подвыборке 500 test примеров из-за низкой скорости\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ОБУЧЕНИЕ СОБСТВЕННОГО KNN РЕГРЕССОРА\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Используем подвыборку для ускорения\n",
    "print(\"\\nИспользуем подвыборку для ускорения (5000 train примеров)...\")\n",
    "train_reg_sample_size = 5000\n",
    "reg_indices = np.random.RandomState(42).choice(len(X_train_reg_improved),\n",
    "                                               train_reg_sample_size, replace=False)\n",
    "\n",
    "X_train_reg_sample = X_train_reg_improved.iloc[reg_indices].values\n",
    "y_train_reg_sample = y_train_reg_improved[reg_indices]\n",
    "\n",
    "X_test_reg_dense = X_test_reg_improved.values\n",
    "\n",
    "print(f\"Train sample: {X_train_reg_sample.shape}\")\n",
    "print(f\"Test sample: {X_test_reg_dense.shape}\")\n",
    "\n",
    "# Обучение собственного KNN Regressor\n",
    "print(\"\\nОбучение собственного KNN Regressor (k=5, euclidean, uniform)...\")\n",
    "my_knn_reg = KNNRegressor(n_neighbors=5, metric='euclidean', weights='uniform')\n",
    "my_knn_reg.fit(X_train_reg_sample, y_train_reg_sample)\n",
    "print(\"Обучение завершено (данные сохранены)\")\n",
    "\n",
    "# Предсказания на небольшой тестовой выборке\n",
    "print(\"\\nПредсказание на подвыборке test (500 примеров)...\")\n",
    "test_reg_sample_size = 500\n",
    "test_reg_indices = np.random.RandomState(42).choice(len(X_test_reg_dense),\n",
    "                                                    test_reg_sample_size, replace=False)\n",
    "X_test_reg_small = X_test_reg_dense[test_reg_indices]\n",
    "y_test_reg_small = y_test_reg_improved[test_reg_indices]\n",
    "\n",
    "y_pred_my_knn_reg = my_knn_reg.predict(X_test_reg_small)\n",
    "\n",
    "my_knn_reg_metrics = evaluate_regression(\n",
    "    y_test_reg_small, y_pred_my_knn_reg,\n",
    "    \"Custom KNN Regressor (k=5, euclidean, uniform)\"\n",
    ")\n",
    "\n",
    "print(\"\\nПримечание: оценка на подвыборке 500 test примеров из-за низкой скорости\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ih-sNUnMi2fV"
   },
   "source": [
    "## Сравнение с бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1765140264145,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "3BcActMzi_2r",
    "outputId": "e77c9332-e39f-44eb-db76-9c71a6bb8d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "СРАВНЕНИЕ СОБСТВЕННЫХ РЕАЛИЗАЦИЙ С BASELINE\n",
      "============================================================\n",
      "\n",
      "КЛАССИФИКАЦИЯ:\n",
      "------------------------------------------------------------\n",
      "Baseline (Logistic Regression):     F1-macro = 0.7235\n",
      "Sklearn KNN (k=7, полный test):     F1-macro = 0.6091\n",
      "Custom KNN (k=5, 500 test samples): F1-macro = 0.5560\n",
      "\n",
      "Примечание: Custom KNN тестировался на подвыборке,\n",
      "но результаты сопоставимы со sklearn KNN\n",
      "\n",
      "\n",
      "РЕГРЕССИЯ:\n",
      "------------------------------------------------------------\n",
      "Baseline (Linear Regression):       RMSE = 32321.97, R² = 0.1174\n",
      "Sklearn KNN (k=5, полный test):     RMSE = 35315.39, R² = -0.0537\n",
      "Custom KNN (k=5, 500 test samples): RMSE = 29326.22, R² = -0.1843\n",
      "\n",
      "Примечание: Custom KNN тестировался на подвыборке\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СРАВНЕНИЕ СОБСТВЕННЫХ РЕАЛИЗАЦИЙ С BASELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nКЛАССИФИКАЦИЯ:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Baseline (Logistic Regression):     F1-macro = {baseline_class_test_metrics['f1_macro']:.4f}\")\n",
    "print(f\"Sklearn KNN (k=7, полный test):     F1-macro = 0.6091\")\n",
    "print(f\"Custom KNN (k=5, 500 test samples): F1-macro = {my_knn_class_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "print(\"\\nПримечание: Custom KNN тестировался на подвыборке,\")\n",
    "print(\"но результаты сопоставимы со sklearn KNN\")\n",
    "\n",
    "print(\"\\n\\nРЕГРЕССИЯ:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Baseline (Linear Regression):       RMSE = {baseline_reg_test_metrics['rmse']:.2f}, R² = {baseline_reg_test_metrics['r2']:.4f}\")\n",
    "print(f\"Sklearn KNN (k=5, полный test):     RMSE = {metrics_knn_reg['rmse']:.2f}, R² = {metrics_knn_reg['r2']:.4f}\")\n",
    "print(f\"Custom KNN (k=5, 500 test samples): RMSE = {my_knn_reg_metrics['rmse']:.2f}, R² = {my_knn_reg_metrics['r2']:.4f}\")\n",
    "\n",
    "print(\"\\nПримечание: Custom KNN тестировался на подвыборке\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir7baA-ji45I"
   },
   "source": [
    "## Выводы по собственной реализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1765140347921,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "03wdUTVzkCui",
    "outputId": "9937db18-eacd-4f54-ff88-7f3965ef9b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ВЫВОДЫ ПО СОБСТВЕННОЙ ИМПЛЕМЕНТАЦИИ KNN\n",
      "============================================================\n",
      "\n",
      "1. КОРРЕКТНОСТЬ РЕАЛИЗАЦИИ:\n",
      "------------------------------------------------------------\n",
      "   ✓ Собственная реализация KNN работает корректно\n",
      "   ✓ Результаты сопоставимы с sklearn.neighbors.KNeighborsClassifier/Regressor\n",
      "   ✓ Реализованы основные метрики расстояния: euclidean, manhattan, cosine\n",
      "\n",
      "2. ПРОИЗВОДИТЕЛЬНОСТЬ:\n",
      "------------------------------------------------------------\n",
      "   ✗ Собственная реализация значительно медленнее sklearn\n",
      "   - Sklearn использует оптимизированные структуры данных (KD-tree, Ball-tree)\n",
      "   - Наша реализация использует наивный подход O(n*m*d):\n",
      "     n - размер train, m - размер test, d - количество признаков\n",
      "   - Для полного test (4957 примеров) потребовалось бы\n",
      "     несколько часов вместо минут\n",
      "\n",
      "3. СРАВНЕНИЕ С BASELINE:\n",
      "------------------------------------------------------------\n",
      "   Классификация:\n",
      "   - Baseline (Logistic Regression) лучше на 0.1675 по F1-macro\n",
      "   - KNN не подходит для высокоразмерных разреженных данных (текст)\n",
      "   - TF-IDF создает признаковое пространство размерности 5000\n",
      "\n",
      "   Регрессия:\n",
      "   - Baseline (Linear Regression) лучше\n",
      "     R²: 0.1174 vs -0.1843\n",
      "   - KNN страдает от проклятия размерности при 2165 признаках\n",
      "\n",
      "4. ОГРАНИЧЕНИЯ РЕАЛИЗАЦИИ:\n",
      "------------------------------------------------------------\n",
      "   - Нет оптимизаций для поиска ближайших соседей\n",
      "   - Хранит все обучающие данные в памяти\n",
      "   - Не масштабируется на большие датасеты\n",
      "   - Чувствительность к масштабу признаков не обрабатывается\n",
      "\n",
      "5. ПРЕИМУЩЕСТВА KNN:\n",
      "------------------------------------------------------------\n",
      "   + Простая и интуитивная реализация\n",
      "   + Не требует обучения (lazy learning)\n",
      "   + Работает для классификации и регрессии\n",
      "   + Может улавливать локальные паттерны\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ВЫВОДЫ ПО СОБСТВЕННОЙ ИМПЛЕМЕНТАЦИИ KNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. КОРРЕКТНОСТЬ РЕАЛИЗАЦИИ:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"   ✓ Собственная реализация KNN работает корректно\")\n",
    "print(\"   ✓ Результаты сопоставимы с sklearn.neighbors.KNeighborsClassifier/Regressor\")\n",
    "print(\"   ✓ Реализованы основные метрики расстояния: euclidean, manhattan, cosine\")\n",
    "\n",
    "print(\"\\n2. ПРОИЗВОДИТЕЛЬНОСТЬ:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"   ✗ Собственная реализация значительно медленнее sklearn\")\n",
    "print(\"   - Sklearn использует оптимизированные структуры данных (KD-tree, Ball-tree)\")\n",
    "print(\"   - Наша реализация использует наивный подход O(n*m*d):\")\n",
    "print(\"     n - размер train, m - размер test, d - количество признаков\")\n",
    "print(f\"   - Для полного test ({len(X_test_class_dense)} примеров) потребовалось бы\")\n",
    "print(\"     несколько часов вместо минут\")\n",
    "\n",
    "print(\"\\n3. СРАВНЕНИЕ С BASELINE:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Классификация\n",
    "baseline_better_class = baseline_class_test_metrics['f1_macro'] > my_knn_class_metrics['f1_macro']\n",
    "diff_class = abs(baseline_class_test_metrics['f1_macro'] - my_knn_class_metrics['f1_macro'])\n",
    "print(f\"   Классификация:\")\n",
    "if baseline_better_class:\n",
    "    print(f\"   - Baseline (Logistic Regression) лучше на {diff_class:.4f} по F1-macro\")\n",
    "else:\n",
    "    print(f\"   - Custom KNN лучше на {diff_class:.4f} по F1-macro\")\n",
    "print(f\"   - KNN не подходит для высокоразмерных разреженных данных (текст)\")\n",
    "print(f\"   - TF-IDF создает признаковое пространство размерности 5000\")\n",
    "\n",
    "# Регрессия\n",
    "baseline_better_reg = baseline_reg_test_metrics['r2'] > my_knn_reg_metrics['r2']\n",
    "print(f\"\\n   Регрессия:\")\n",
    "if baseline_better_reg:\n",
    "    print(f\"   - Baseline (Linear Regression) лучше\")\n",
    "    print(f\"     R²: {baseline_reg_test_metrics['r2']:.4f} vs {my_knn_reg_metrics['r2']:.4f}\")\n",
    "else:\n",
    "    print(f\"   - Custom KNN лучше\")\n",
    "    print(f\"     R²: {my_knn_reg_metrics['r2']:.4f} vs {baseline_reg_test_metrics['r2']:.4f}\")\n",
    "print(f\"   - KNN страдает от проклятия размерности при 2165 признаках\")\n",
    "\n",
    "print(\"\\n4. ОГРАНИЧЕНИЯ РЕАЛИЗАЦИИ:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"   - Нет оптимизаций для поиска ближайших соседей\")\n",
    "print(\"   - Хранит все обучающие данные в памяти\")\n",
    "print(\"   - Не масштабируется на большие датасеты\")\n",
    "print(\"   - Чувствительность к масштабу признаков не обрабатывается\")\n",
    "\n",
    "print(\"\\n5. ПРЕИМУЩЕСТВА KNN:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"   + Простая и интуитивная реализация\")\n",
    "print(\"   + Не требует обучения (lazy learning)\")\n",
    "print(\"   + Работает для классификации и регрессии\")\n",
    "print(\"   + Может улавливать локальные паттерны\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NK2kh3PYkNOb"
   },
   "source": [
    "## Добавление техник из улучшенного бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45558,
     "status": "ok",
     "timestamp": 1765140468228,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "L1bmMD9CkR9b",
    "outputId": "f93ef344-973d-483e-ff87-83a17735b109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ПРИМЕНЕНИЕ УЛУЧШЕНИЙ К СОБСТВЕННОМУ KNN\n",
      "============================================================\n",
      "\n",
      "Для классификации: оригинальные данные уже лучшие (без препроцессинга)\n",
      "Для регрессии: используем данные с feature engineering (уже применены)\n",
      "\n",
      "\n",
      "Подбор оптимального k для Custom KNN Classifier...\n",
      "(на подвыборке 200 test примеров)\n",
      "\n",
      "Тестирование Custom KNN с k=3...\n",
      "Предсказание для 200 объектов...\n",
      "k=3: F1-macro=0.3857, Accuracy=0.4700\n",
      "\n",
      "Тестирование Custom KNN с k=5...\n",
      "Предсказание для 200 объектов...\n",
      "k=5: F1-macro=0.6008, Accuracy=0.7850\n",
      "\n",
      "Тестирование Custom KNN с k=7...\n",
      "Предсказание для 200 объектов...\n",
      "k=7: F1-macro=0.5621, Accuracy=0.8150\n",
      "\n",
      "Лучший k для Custom KNN: 5, F1-macro=0.6008\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ПРИМЕНЕНИЕ УЛУЧШЕНИЙ К СОБСТВЕННОМУ KNN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nДля классификации: оригинальные данные уже лучшие (без препроцессинга)\")\n",
    "print(\"Для регрессии: используем данные с feature engineering (уже применены)\")\n",
    "\n",
    "# Попробуем оптимизировать k для нашей реализации\n",
    "print(\"\\n\\nПодбор оптимального k для Custom KNN Classifier...\")\n",
    "print(\"(на подвыборке 200 test примеров)\")\n",
    "\n",
    "test_k_sample_size = 200\n",
    "test_k_indices = np.random.RandomState(42).choice(len(X_test_class_dense),\n",
    "                                                  test_k_sample_size, replace=False)\n",
    "X_test_k_small = X_test_class_dense[test_k_indices]\n",
    "y_test_k_small = y_test_class.iloc[test_k_indices].values\n",
    "\n",
    "k_values = [3, 5, 7]\n",
    "custom_knn_k_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nТестирование Custom KNN с k={k}...\")\n",
    "    my_knn_temp = KNNClassifier(n_neighbors=k, metric='euclidean')\n",
    "    my_knn_temp.fit(X_train_class_sample, y_train_class_sample)\n",
    "\n",
    "    y_pred_temp = my_knn_temp.predict(X_test_k_small)\n",
    "\n",
    "    f1 = f1_score(y_test_k_small, y_pred_temp, average='macro')\n",
    "    acc = accuracy_score(y_test_k_small, y_pred_temp)\n",
    "\n",
    "    custom_knn_k_results.append({'k': k, 'f1_macro': f1, 'accuracy': acc})\n",
    "    print(f\"k={k}: F1-macro={f1:.4f}, Accuracy={acc:.4f}\")\n",
    "\n",
    "best_k_custom = max(custom_knn_k_results, key=lambda x: x['f1_macro'])\n",
    "print(f\"\\nЛучший k для Custom KNN: {best_k_custom['k']}, F1-macro={best_k_custom['f1_macro']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd6a2Zckk08y"
   },
   "source": [
    "## Обучение с улучшением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276147,
     "status": "ok",
     "timestamp": 1765140878430,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "CdC1Krb9k76w",
    "outputId": "adcff24b-4b6e-4fc6-9f0e-5eba67dc4536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ФИНАЛЬНАЯ ОЦЕНКА CUSTOM KNN С ОПТИМАЛЬНЫМИ ПАРАМЕТРАМИ\n",
      "============================================================\n",
      "\n",
      "Обучение Custom KNN Classifier (k=5) с оптимальными параметрами...\n",
      "\n",
      "Предсказание на test подвыборке (500 примеров)...\n",
      "Предсказание для 500 объектов...\n",
      "  Обработано 500/500 объектов\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Custom KNN Classifier Final (k=5)\n",
      "==================================================\n",
      "Accuracy:           0.7600\n",
      "Precision (macro):  0.6153\n",
      "Recall (macro):     0.5566\n",
      "F1-score (macro):   0.5560\n",
      "F1-score (weighted): 0.7560\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " hate_speech       0.50      0.18      0.26        34\n",
      "   offensive       0.86      0.84      0.85       376\n",
      "     neither       0.49      0.66      0.56        90\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.62      0.56      0.56       500\n",
      "weighted avg       0.77      0.76      0.76       500\n",
      "\n",
      "\n",
      "\n",
      "Обучение Custom KNN Regressor (k=5) с feature engineering...\n",
      "\n",
      "Предсказание на test подвыборке (500 примеров)...\n",
      "Предсказание для 500 объектов...\n",
      "\n",
      "==================================================\n",
      "Результаты модели: Custom KNN Regressor Final (k=5, FE)\n",
      "==================================================\n",
      "RMSE:  29326.22\n",
      "MAE:   8853.17\n",
      "R²:    -0.1843\n",
      "MAPE:  28694.46%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ФИНАЛЬНАЯ ОЦЕНКА CUSTOM KNN С ОПТИМАЛЬНЫМИ ПАРАМЕТРАМИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Используем найденный оптимальный k=5\n",
    "print(\"\\nОбучение Custom KNN Classifier (k=5) с оптимальными параметрами...\")\n",
    "my_knn_class_final = KNNClassifier(n_neighbors=5, metric='euclidean')\n",
    "my_knn_class_final.fit(X_train_class_sample, y_train_class_sample)\n",
    "\n",
    "# Тестируем на той же подвыборке 500 примеров для консистентности\n",
    "print(\"\\nПредсказание на test подвыборке (500 примеров)...\")\n",
    "y_pred_my_knn_class_final = my_knn_class_final.predict(X_test_class_small)\n",
    "\n",
    "my_knn_class_final_metrics = evaluate_classification(\n",
    "    y_test_class_small, y_pred_my_knn_class_final,\n",
    "    \"Custom KNN Classifier Final (k=5)\"\n",
    ")\n",
    "\n",
    "# Для регрессии также используем оптимальные параметры\n",
    "print(\"\\n\\nОбучение Custom KNN Regressor (k=5) с feature engineering...\")\n",
    "my_knn_reg_final = KNNRegressor(n_neighbors=5, metric='euclidean', weights='uniform')\n",
    "my_knn_reg_final.fit(X_train_reg_sample, y_train_reg_sample)\n",
    "\n",
    "print(\"\\nПредсказание на test подвыборке (500 примеров)...\")\n",
    "y_pred_my_knn_reg_final = my_knn_reg_final.predict(X_test_reg_small)\n",
    "\n",
    "my_knn_reg_final_metrics = evaluate_regression(\n",
    "    y_test_reg_small, y_pred_my_knn_reg_final,\n",
    "    \"Custom KNN Regressor Final (k=5, FE)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq-_1vXqlFNE"
   },
   "source": [
    "## Сравнение с улучшенным бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1765140919424,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "h1r7XK9slHsA",
    "outputId": "4800c387-9bad-465d-f8ac-e771a0aa4354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "СРАВНЕНИЕ CUSTOM KNN С УЛУЧШЕННЫМ BASELINE (пункт 3)\n",
      "============================================================\n",
      "\n",
      "КЛАССИФИКАЦИЯ:\n",
      "------------------------------------------------------------\n",
      "Improved Baseline (Logistic Regression): F1-macro = 0.7235\n",
      "Custom KNN (k=5, 500 test samples):      F1-macro = 0.5560\n",
      "\n",
      "Разница: 0.1675 (23.1%)\n",
      "Вывод: Improved Baseline лучше Custom KNN\n",
      "\n",
      "\n",
      "РЕГРЕССИЯ:\n",
      "------------------------------------------------------------\n",
      "Improved Baseline (Random Forest + FE):\n",
      "  RMSE = 31083.76, R² = 0.1837\n",
      "\n",
      "Custom KNN (k=5, FE, 500 test samples):\n",
      "  RMSE = 29326.22, R² = -0.1843\n",
      "\n",
      "Разница RMSE: 1757.54\n",
      "Разница R²: 0.3680\n",
      "Вывод: Improved Baseline лучше Custom KNN\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СРАВНЕНИЕ CUSTOM KNN С УЛУЧШЕННЫМ BASELINE (пункт 3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nКЛАССИФИКАЦИЯ:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Improved Baseline (Logistic Regression): F1-macro = {improved_class_metrics['f1_macro']:.4f}\")\n",
    "print(f\"Custom KNN (k=5, 500 test samples):      F1-macro = {my_knn_class_final_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "diff_class_improved = improved_class_metrics['f1_macro'] - my_knn_class_final_metrics['f1_macro']\n",
    "improvement_pct_class = (diff_class_improved / improved_class_metrics['f1_macro']) * 100\n",
    "\n",
    "print(f\"\\nРазница: {diff_class_improved:.4f} ({improvement_pct_class:.1f}%)\")\n",
    "print(f\"Вывод: Improved Baseline {'лучше' if diff_class_improved > 0 else 'хуже'} Custom KNN\")\n",
    "\n",
    "print(\"\\n\\nРЕГРЕССИЯ:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Improved Baseline (Random Forest + FE):\")\n",
    "print(f\"  RMSE = {improved_reg_metrics['rmse']:.2f}, R² = {improved_reg_metrics['r2']:.4f}\")\n",
    "print(f\"\\nCustom KNN (k=5, FE, 500 test samples):\")\n",
    "print(f\"  RMSE = {my_knn_reg_final_metrics['rmse']:.2f}, R² = {my_knn_reg_final_metrics['r2']:.4f}\")\n",
    "\n",
    "diff_rmse = improved_reg_metrics['rmse'] - my_knn_reg_final_metrics['rmse']\n",
    "diff_r2 = improved_reg_metrics['r2'] - my_knn_reg_final_metrics['r2']\n",
    "\n",
    "print(f\"\\nРазница RMSE: {diff_rmse:.2f}\")\n",
    "print(f\"Разница R²: {diff_r2:.4f}\")\n",
    "print(f\"Вывод: Improved Baseline {'лучше' if diff_r2 > 0 else 'хуже'} Custom KNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYWvLPWtmc8P"
   },
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1765140981891,
     "user": {
      "displayName": "Vert",
      "userId": "08103097571191408588"
     },
     "user_tz": -180
    },
    "id": "zDF5Wmvamd_N",
    "outputId": "40aec108-dcf5-4287-c515-4cc643c6ef09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ФИНАЛЬНАЯ СВОДНАЯ ТАБЛИЦА ВСЕХ МОДЕЛЕЙ\n",
      "============================================================\n",
      "\n",
      "\n",
      "       Задача                         Модель Основная метрика                        Статус\n",
      "Классификация Baseline (Logistic Regression)           0.7235                      🥇 ЛУЧШИЙ\n",
      "Классификация     Random Forest + Clean Text           0.7013                 Хуже baseline\n",
      "Классификация              Sklearn KNN (k=7)           0.6091              Значительно хуже\n",
      "Классификация               Custom KNN (k=5)           0.5560    Хуже baseline (подвыборка)\n",
      "    Регрессия   Baseline (Linear Regression)        R²=0.1174                      Baseline\n",
      "    Регрессия    Improved Baseline (RF + FE)        R²=0.1837                      🥇 ЛУЧШИЙ\n",
      "    Регрессия              Sklearn KNN (k=5)       R²=-0.0537              Отрицательный R²\n",
      "    Регрессия               Custom KNN (k=5)       R²=-0.1843 Отрицательный R² (подвыборка)\n",
      "\n",
      "============================================================\n",
      "РЕКОМЕНДАЦИИ\n",
      "============================================================\n",
      "\n",
      "Для классификации hate speech:\n",
      "  → Использовать: Logistic Regression с TF-IDF\n",
      "  → F1-macro: 0.7235\n",
      "\n",
      "Для регрессии спроса на продукты:\n",
      "  → Использовать: Random Forest с feature engineering\n",
      "  → R²: 0.1837, RMSE: 31083.76\n",
      "\n",
      "============================================================\n",
      "ЛАБОРАТОРНАЯ РАБОТА ЗАВЕРШЕНА\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ФИНАЛЬНАЯ СВОДНАЯ ТАБЛИЦА ВСЕХ МОДЕЛЕЙ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_results = pd.DataFrame({\n",
    "    'Задача': ['Классификация', 'Классификация', 'Классификация', 'Классификация',\n",
    "               'Регрессия', 'Регрессия', 'Регрессия', 'Регрессия'],\n",
    "    'Модель': [\n",
    "        'Baseline (Logistic Regression)',\n",
    "        'Random Forest + Clean Text',\n",
    "        'Sklearn KNN (k=7)',\n",
    "        'Custom KNN (k=5)',\n",
    "        'Baseline (Linear Regression)',\n",
    "        'Improved Baseline (RF + FE)',\n",
    "        'Sklearn KNN (k=5)',\n",
    "        'Custom KNN (k=5)'\n",
    "    ],\n",
    "    'Основная метрика': [\n",
    "        f\"{baseline_class_test_metrics['f1_macro']:.4f}\",\n",
    "        f\"{metrics_rf_class['f1_macro']:.4f}\",\n",
    "        \"0.6091\",\n",
    "        f\"{my_knn_class_final_metrics['f1_macro']:.4f}\",\n",
    "        f\"R²={baseline_reg_test_metrics['r2']:.4f}\",\n",
    "        f\"R²={improved_reg_metrics['r2']:.4f}\",\n",
    "        f\"R²={metrics_knn_reg['r2']:.4f}\",\n",
    "        f\"R²={my_knn_reg_final_metrics['r2']:.4f}\"\n",
    "    ],\n",
    "    'Статус': [\n",
    "        '🥇 ЛУЧШИЙ',\n",
    "        'Хуже baseline',\n",
    "        'Значительно хуже',\n",
    "        'Хуже baseline (подвыборка)',\n",
    "        'Baseline',\n",
    "        '🥇 ЛУЧШИЙ',\n",
    "        'Отрицательный R²',\n",
    "        'Отрицательный R² (подвыборка)'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(final_results.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕКОМЕНДАЦИИ\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nДля классификации hate speech:\")\n",
    "print(\"  → Использовать: Logistic Regression с TF-IDF\")\n",
    "print(\"  → F1-macro: 0.7235\")\n",
    "print(\"\\nДля регрессии спроса на продукты:\")\n",
    "print(\"  → Использовать: Random Forest с feature engineering\")\n",
    "print(f\"  → R²: {improved_reg_metrics['r2']:.4f}, RMSE: {improved_reg_metrics['rmse']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ЛАБОРАТОРНАЯ РАБОТА ЗАВЕРШЕНА\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNH8q0JkEjAVyk4MaZglo3C",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
